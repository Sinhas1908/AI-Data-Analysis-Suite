{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a92f0479-ed37-4ad5-92f6-7fd2558ac580",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-19 09:47:40,382 - httpx - INFO - HTTP Request: GET http://127.0.0.1:7861/gradio_api/startup-events \"HTTP/1.1 200 OK\"\n",
      "2025-02-19 09:47:40,396 - httpx - INFO - HTTP Request: HEAD http://127.0.0.1:7861/ \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7861\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-19 09:47:41,245 - httpx - INFO - HTTP Request: GET https://api.gradio.app/pkg-version \"HTTP/1.1 200 OK\"\n",
      "2025-02-19 09:47:41,861 - httpx - INFO - HTTP Request: GET https://api.gradio.app/v3/tunnel-request \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on public URL: https://e08b76066065ede033.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-19 09:47:44,996 - httpx - INFO - HTTP Request: HEAD https://e08b76066065ede033.gradio.live \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://e08b76066065ede033.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import logging\n",
    "import gradio as gr\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from openai import OpenAI\n",
    "from gtts import gTTS\n",
    "import tempfile\n",
    "from typing import Tuple, Dict, Any\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO,\n",
    "                    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# Initialize OpenAI client\n",
    "client = OpenAI(api_key=(\"Your_OpenAI_API\"))\n",
    "\n",
    "# Constants\n",
    "MAX_ROWS = 1000\n",
    "MAX_COLS = 50   \n",
    "VALID_FILE_TYPES = [\".csv\", \".xlsx\", \".xls\"]\n",
    "SUPPORTED_AUDIO_FORMATS = [\"wav\", \"mp3\", \"ogg\"]\n",
    "\n",
    "class DataAnalyzer:\n",
    "    def __init__(self):\n",
    "        self.logger = logging.getLogger(__name__)\n",
    "        \n",
    "    def validate_file(self, file_path: str) -> bool:\n",
    "        if not any(file_path.endswith(ext) for ext in VALID_FILE_TYPES):\n",
    "            raise ValueError(\"Unsupported file format. Please upload CSV or Excel file.\")\n",
    "        return True\n",
    "\n",
    "    def read_data(self, file_path: str) -> pd.DataFrame:\n",
    "        try:\n",
    "            self.validate_file(file_path)\n",
    "            if file_path.endswith(\".csv\"):\n",
    "                df = pd.read_csv(file_path, encoding_errors='replace')\n",
    "            else:\n",
    "                df = pd.read_excel(file_path)\n",
    "            \n",
    "            df = df.dropna(how='all').dropna(how='all', axis=1)\n",
    "            return df.iloc[:MAX_ROWS, :MAX_COLS]\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error reading file: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "    def generate_summary(self, df: pd.DataFrame) -> Dict[str, Any]:\n",
    "        summary = {\n",
    "            \"data_types\": df.dtypes.astype(str).to_dict(),\n",
    "            \"missing_values\": df.isnull().sum().to_dict(),\n",
    "            \"numeric_summary\": df.describe().to_dict() if df.select_dtypes(include=np.number).shape[1] > 0 else {},\n",
    "            \"categorical_summary\": {col: df[col].value_counts().to_dict() \n",
    "                                   for col in df.select_dtypes(include='object').columns}\n",
    "        }\n",
    "        return summary\n",
    "\n",
    "class AIService:\n",
    "    def __init__(self):\n",
    "        self.logger = logging.getLogger(__name__)\n",
    "    \n",
    "    def get_ai_response(self, system_prompt: str, user_prompt: str) -> str:\n",
    "        try:\n",
    "            response = client.chat.completions.create(\n",
    "                model=\"gpt-4-turbo\",\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": system_prompt},\n",
    "                    {\"role\": \"user\", \"content\": user_prompt}\n",
    "                ],\n",
    "                temperature=0.3,\n",
    "                max_tokens=1500\n",
    "            )\n",
    "            return response.choices[0].message.content\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"OpenAI API Error: {str(e)}\")\n",
    "            return f\"AI Service Error: {str(e)}\"\n",
    "    \n",
    "    def generate_insights(self, df: pd.DataFrame, prompt: str) -> str:\n",
    "        system_prompt = f\"You are a senior data scientist. Analyze this data and provide insights based on: {prompt}\"\n",
    "        data_preview = f\"Data Columns: {list(df.columns)}\\nSample Data:\\n{df.head(3).to_string()}\"\n",
    "        return self.get_ai_response(system_prompt, data_preview + prompt)\n",
    "\n",
    "class AudioService:\n",
    "    @staticmethod\n",
    "    def text_to_speech(text: str) -> Tuple[str, str]:\n",
    "        try:\n",
    "            with tempfile.NamedTemporaryFile(suffix=\".mp3\", delete=False) as fp:\n",
    "                tts = gTTS(text=text, lang='en', slow=False)\n",
    "                tts.save(fp.name)\n",
    "                return fp.name, None\n",
    "        except Exception as e:\n",
    "            logging.error(f\"TTS Error: {str(e)}\")\n",
    "            return None, str(e)\n",
    "    \n",
    "    @staticmethod\n",
    "    def speech_to_text(audio_path: str) -> Tuple[str, str]:\n",
    "        try:\n",
    "            with open(audio_path, \"rb\") as audio_file:\n",
    "                transcript = client.audio.transcriptions.create(\n",
    "                    model=\"whisper-1\",\n",
    "                    file=audio_file\n",
    "                )\n",
    "                return transcript.text, None\n",
    "        except Exception as e:\n",
    "            logging.error(f\"STT Error: {str(e)}\")\n",
    "            return None, str(e)\n",
    "\n",
    "# Initialize services\n",
    "data_analyzer = DataAnalyzer()\n",
    "ai_service = AIService()\n",
    "audio_service = AudioService()\n",
    "\n",
    "def process_inputs(file_path: str, prompt: str, audio_input: str) -> Tuple:\n",
    "    try:\n",
    "        if audio_input:\n",
    "            transcript, error = audio_service.speech_to_text(audio_input)\n",
    "            if error:\n",
    "                raise ValueError(f\"Speech recognition error: {error}\")\n",
    "            prompt = f\"{prompt}\\n[Voice Input]: {transcript}\" if prompt else transcript\n",
    "\n",
    "        df = data_analyzer.read_data(file_path)\n",
    "        insights = ai_service.generate_insights(df, prompt)\n",
    "        eda_report = ai_service.get_ai_response(\n",
    "            system_prompt=f\"Provide an EDA report based on {prompt}\",\n",
    "            user_prompt=f\"Data Summary:\\n{data_analyzer.generate_summary(df)}\"\n",
    "        )\n",
    "        insight_audio, _ = audio_service.text_to_speech(insights)\n",
    "        eda_audio, _ = audio_service.text_to_speech(eda_report)\n",
    "        return insights, eda_report, insight_audio, eda_audio\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Processing Error: {str(e)}\")\n",
    "        return str(e), str(e), None, None\n",
    "\n",
    "with gr.Blocks(title=\"AI Data Analysis Suite\") as app:\n",
    "    gr.Markdown(\"# AI Data Analysis Suite ðŸ§ \")\n",
    "    with gr.Row():\n",
    "        with gr.Column():\n",
    "            file_input = gr.File(label=\"Upload Data\", file_types=VALID_FILE_TYPES)\n",
    "            prompt_input = gr.Textbox(label=\"Enter Prompt\")\n",
    "            audio_input = gr.Audio(label=\"Or Speak Your Prompt\", sources=[\"microphone\"], type=\"filepath\")\n",
    "            process_btn = gr.Button(\"Analyze\")\n",
    "        with gr.Column():\n",
    "            insights_output = gr.Textbox(label=\"AI Insights\")\n",
    "            insight_audio = gr.Audio(label=\"AI Audio Insights\")\n",
    "            eda_output = gr.Textbox(label=\"EDA Report\")\n",
    "            eda_audio = gr.Audio(label=\"EDA Audio Report\")\n",
    "    process_btn.click(fn=process_inputs, inputs=[file_input, prompt_input, audio_input], outputs=[insights_output, eda_output, insight_audio, eda_audio])\n",
    "if __name__ == \"__main__\":\n",
    "    app.launch(share=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4ef67cd-c977-4547-95e1-05696a25fd6a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
